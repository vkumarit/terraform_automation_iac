Terraform 
---------

# Azure Authentication #

>>> Server-side/backend Alternatives for Terraform Authentication <<<

I. Using Service Principal secrets (tenant_id, subscription_id, client_id, client_secret)

A) For first time/step, also when we exit the session with exported vars and
   starting new session. The typical secure workflow is:

> a) > Create an App Registration (Service Principal) in Azure Portal
  - Register an application in Azure AD.
  - Note the Client ID, Tenant ID.
  - Generate a Client Secret.
  - Assign the Service Principal the necessary roles (e.g., Contributor) 
    on your subscription or resource group.
  - generate Personam Access Token from azure organization to setup agent on vm.
  
  b) > Create Service Principal using Azure AD CLI
  - Log into Azure (Cloud Shell or local machine) and do:
    $ az ad sp create-for-rbac --name "terraform-ec2-sp" --role Contributor \
        --scopes /subscriptions/<SUBSCRIPTION_ID> --sdk-auth
    This prints JSON including clientId (AppId), clientSecret, tenantId, subscriptionId. Store them 
    securely and use on the EC2 instance.
(SKIP IF APP REGISTRATION DONE)
  * For key vault access assign 'get' access to this service principal when needed to fetch secrets from      key vault

## Azure authentication from outside Azure (like terraform on EC2) ##

> b) > Export the Service Principal credentials as environment variables on our EC2 instance, do bash
  $ export ARM_CLIENT_ID="<client-id-from-app-registration>"
  $ export ARM_CLIENT_SECRET="<client-secret-from-app-registration>"
  $ export ARM_SUBSCRIPTION_ID="<our-subscription-id>"
  $ export ARM_TENANT_ID="<tenant-id-from-app-registration>"
  This enables Terraform to authenticate securely without embedding secrets in code.
  Terraform will read the ARM_* env vars and authenticate, can use below provider block at minimum:
	provider "azurerm" {
	  features {}
	}

  Change the exported env vars as
    1) To see all env vars,
       $ env or printenv
    2) filter by pattern
       $ printenv | grep ARM_* 
    3) To check single variable,
       $ echo $ARM_CLIENT_ID
    4) To reset a variable export it again as
       $ export ARM_CLIENT_ID="new-client-id"
    5) Remove from current shell,
       $ unset ARM_CLIENT_SECRET

  Also used in dev, test environment.

or,

  b) > Azure CLI Interactive or Service Principal Login:
  - Run 'az login' (interactive or with SP credentials) on your EC2 instance before running Terraform.
    $ az login \
        --service-principal \
        --username <clientId> \
        --password <clientSecret> \
        --tenant <tenantId>
    
    If getting error 'No subscriptions found for <client-Id>.`, go to subscription > IAM > 
    Add role assignment > Role > Priviledged admin. roles > select 'Owner'/'contributor' > Members > User,         group, or service principal > Select members > 'az-classic-app' (name of app registered)> assigns role 
    'owner' at scope 'This resource'.

  - Verify the subscription used by terraform.
    $ az account show
    
  - Configure Terraform to use AzureRM provider
  
    Terraform >=4 requires subscription_id for azure authentication, so
    i) Export subscription id to env vars,
       $ export ARM_SUBSCRIPTION_ID="<our-subscription-id>" 
       
       terraform {
         required_providers {
           azurerm = {
             source  = "hashicorp/azurerm"
             version = "~> 4.0"
          }
         }
       }
    
       provider "azurerm" {
         features {}
       }
    
    ii) Hardcode subscription id as below without exporting to env vars,
       provider "azurerm" {
         features         {}
         subscription_id  = "<-subscription_id->"
       }
    
    iii) Else, after exporting id to env vars, explicitly reference as a variable
       variable "subscription_id" {
          description = "Azure subscription ID"
          type        = string
          default     = null  # Falls back to env var
       }

       provider "azurerm" {
         features         {}
         subscription_id  = var.subscription_id
       }

    

    When the Azure CLI is logged in with a user? or service principal, AzureRM can automatically use the SP     credentials.

  - Terraform picks up the authentication context from the Azure CLI session.
  Use Case: Manual runs or environments where you can run CLI commands. Can also be used subsequently   afterwards initial setup.

> c) > Run terraform init, plan -out ('-out' so terraform guarantee to act exactly as was shown in plan phase),
       and apply commands EC2 instance. Terraform will use these environment variables (or az login context)
       to authenticate and create our Azure resources including key vault.

or,
     > Use .tfvars file 
  - In variable.tf, mark less-sensitive secret as 'sensitive = true' and keep these less-sensitive secrets
    in .tfvars file 
  - Don't add and push it to version control.
  - Env - test/dev 
  - Not suitable to keep secrets when production env.

or, if

## Azure authentication from inside Azure Resources(VM, Container, DevOps pipeline) ##
 
  b) > Use 'Managed Identity' by adding below to provider.tf. No secrets need to be provided at all,

  provider "azurerm" {
  features = {}
  use_msi  = true
  }

> c) > Run terraform init plan apply commands from our Azure (VM, Container, DevOps pipeline)
  Terraform will use these environment variables to authenticate 
  and create our Azure resources including key vault.


B) For subsequent use, after first step / Authentication is done, switch to using dynamic
   secret fetching from vault
  - Store credentials/secrets in Azure Key Vault or HashiCorp Vault (or other secret managers like of CI/CD platforms as Jenkins).
  - Use 'azurerm_key_vault_secret' data source in Terraform to fetch secrets dynamically during future runs,
    avoiding hardcoding or manually exporting secrets.
  - setup service principal access to key vault secrets with read (get) permissions, 
    for strong access control or limited service principal with permission to read (get) those secrets.

> a) > Go to Azure Dashboard > key vault > Add Secrets
  and/or 
  Add Secrets to Key Vault using azure cli as below:
  az keyvault secret set --vault-name MyKeyVault --name "client-id" --value "<your-client-id>"
  az keyvault secret set --vault-name MyKeyVault --name "client-secret" --value "<your-client-secret>"
  az keyvault secret set --vault-name MyKeyVault --name "subscription-id" --value "<your-subscription-id>"
  az keyvault secret set --vault-name MyKeyVault --name "tenant-id" --value "<your-tenant-id>"

III. Azure AD Workload Identity Federation (OIDC)
  - Federate your CI/CD platform (GitHub Actions, Jenkins, etc.) with Azure AD using OpenID Connect.
  - The CI/CD pipeline presents an identity token to Azure AD, which is mapped to a federated credential.
  - Terraform authenticates with Azure using this token, not secrets.
  - use Azure federated credentials to assign RBAC to the identity group.
  Use Case: Secure CI/CD pipelines, especially for GitHub Actions, Azure DevOps, or other cloud-native   workflows.
  ?? How to generate and use federated token? bootstrap initial run or subsequent usage? steps ?

IV. Use Azure Key Vault Access with Short-Lived Tokens

  - Use a trusted service to generate short-lived access tokens or SAS tokens for Key Vault.
  - Inject these tokens into your environment for each Terraform run.
  Use Case: Highly secure, automated environments with strict secret rotation policies.
  ?? How steps


>>> Frontend Alternatives for Terraform Authentication <<<

V. CI/CD Pipeline Secrets Storage  
  - Use the built-in secrets management features of CI/CD tools 
  - such as GitHub Actions, Azure DevOps, or Jenkins
  - store and encrypt secrets then inject them as environment variables into build and deployment jobs.
  - Env - prod.

 > How to configure CI/CD or automation agents to inject Service Principal secrets as environment 
   variables securely for terraform?
  
  a) With Azure DevOps: 
     In classic pipelines, environment variables mapped in one task do not persist to other tasks.
       1) Secret Variables:
          > Go to Pipelines > Select pipeline > Edit.
          > Click on the Variables tab.
          > Add a new variable (e.g., ARM_CLIENT_SECRET, ARM_CLIENT_ID, ARM_TENANT_ID, ARM_SUBSCRIPTION_ID).
          > Enter value > check Keep this value secret.
          > Save pipeline.
          > Classic Pipeline - Go to Environment Variables, map the secret variable to an environment 
            variable (e.g., variable name as ARM_CLIENT_SECRET and value as $(ARM_CLIENT_SECRET), 
            so Terraform on vm picks them up as ARM_* variables during that tasks' runtime. The pipeline tasks             we do this with are below, 
            i) a Bash or PowerShell script task, in a script body add below and run it,
               
               terraform init
               terraform plan -out=tfplan
               terraform apply tfplan
 
            ii) a Terraform task (by microsoft), configured with Environment Variables as mentioned. 

          > YAML Pipeline - In YAML file, reference the variable as $(ARM_CLIENT_SECRET). 
            To use it in a script, map it to an environment variable as:

            steps:
            - script: |
                echo "Secret value is set"
                # Terraform steps here
              env:
                ARM_CLIENT_SECRET: $(ARM_CLIENT_SECRET)

​
       2) Variable Groups (recommended for reuse, used in production):
          > Go to Azure DevOps project > Pipelines > Library > Click + Variable group.
          > Enter a name for the group (e.g., prod-terraform-vars). 
          > Add variables (e.g., ARM_CLIENT_SECRET, ARM_CLIENT_ID, ARM_TENANT_ID, ARM_SUBSCRIPTION_ID) and 
            check the secret checkbox for sensitive values.
          > Save the variable group.
          > Classic Pipeline - Edit pipeline > Variables tab > Click Link variable group 
            > select prod-terraform-vars group > Save pipeline. 
              In pipeline tasks, under Environment Variables, map the secret variable to an                                   environment variable (e.g., var as ARM_CLIENT_SECRET and value as $(ARM_CLIENT_SECRET),
              so Terraform picks them up as ARM_* variables during that tasks' runtime, The pipeline tasks                    we do this with are below,
              i) a Bash or PowerShell script task, in a script body add below and run it,
                
                terraform init
                terraform plan -out=tfplan
                terraform apply tfplan
 
              ii) a Terraform task (by microsoft), configured with Environment Variables as mentioned. 

          > YAML Pipeline - In 'azure-pipelines.yaml' file, reference the variable group like this:
            
            variables:
            - group: prod-terraform-vars

            steps:
            - script: |
                echo "Using secret ARM_CLIENT_ID" 
                # echoing secrets not recommended
                # Your Terraform steps here
               displayName: Run Terraform

            Secret values will be injected to env and masked in logs and
            Limit access to the variable group and pipeline to authorized users.
            When needed rotate secrets and update variable group.

       3) Variable Groups linked with Key Vault:
          Recommended for production - Store service principal secrets (client secret) and other sensitive                values in Azure Key Vault. Expose them to Azure DevOps pipeline via a variable group linked to 
          that Key Vault.
          i) Store secrets in Azure Key Vault: 
             a) Azure portal > Create/choose Key Vault in prod env, and 
             b) Enable RBAC or vault access policies, 
             c) Restrict access so only few admins and Azure DevOps service principal can read secrets.
             d) Add service principal secrets to Key Vault as 
                tf-ARM-CLIENT-ID(non-prod)/tf-ARM-CLIENT-ID-prod etc.
          ii) Link Key Vault to Azure DevOps (variable group):
             a) Create service connection - 
                Go to Azure DevOps > project > Project settings > Service connections > Create an “Azure                        Resource Manager” service connection that has access to production Key Vault 
                (subscription + proper role, e.g., Key Vault Secrets User / Reader).
             b) Create a variable group linked to Key Vault -
                Go to Pipelines > Library > + Variable group > Name it as 'prod-terraform-kv' 
                > Enable “Link secrets from an Azure Key Vault as variables” > Choose the ARM service                           connection we created > select production Key Vault > Add secrets from vault, 
                like (tf-ARM-CLIENT-ID, etc.) > Save the variable group.
                The actual values stay only in Key Vault, Azure DevOps just references them.
          iii) Connect variable group to the production pipeline -
             a) Open production classic pipeline > click Edit > Variables tab > click “Link variable group”
                > Select 'prod-terraform-kv' variable group > save pipeline.
                > In pipeline tasks, under Environment Variables, map the secret variable to an                                   environment variable (e.g., var as ARM_CLIENT_SECRET and value as $(tf-ARM-CLIENT-SECRET),
                  so Terraform picks them up as ARM_* variables during that tasks' runtime. The pipeline tasks                    we do this with are below,
                  i) a Bash or PowerShell script task, in a script body add below and run it,
                
                     terraform init
                     terraform plan -out=tfplan
                     terraform apply tfplan
 
                  ii) Or, a Terraform task (by microsoft), configured with Environment Variables as mentioned.

             b) YAML Pipeline - In 'azure-pipelines.yaml' file, reference the variable group like this:
            
                variables:
                - group: prod-terraform-vars

                steps:
                - script: |
                    echo "Using secret ARM_CLIENT_ID" 
                    # echoing secrets not recommended
                    # Your Terraform steps here
                  displayName: Run Terraform

                Secret values will be injected to env and masked in logs and
                Limit access to the variable group and pipeline to authorized users.
                When needed rotate secrets from Key Vault.
       
       4)  Use a task such as AzureCLI@2 or the Terraform task - 
           that is bound to an Azure service connection and exports SP details to env vars 
           (via addSpnToEnvironment or similar) before running terraform init/plan/apply. 
           Azure Resource Manager (ARM) service connection - Grants Azure DevOps pipelines the 
           ability to authenticate and manage Azure resources, and it's the connection used by 
           tasks like AzureCLI@2, Azure Resource Group Deployment, and Terraform when set to use
           Azure authentication.
           i) Using AzureCLI@2 - 
                a) Install azure cli on ec2 instance once, manual az login is not required.
                b) Create task AzureCLI@2 in classic pipeline and select ARM service connection (SP) 
                   we created as it leverages the credentials from the ARM service connection 
                   (which is based on service principal) to authenticate and set the environment 
                   variables for pipeline tasks.
                c) Script Type: Choose "Bash" or "shell" (for Linux agents) or 
                   "PowerShell" (for Windows agents).
                d) Script Location: Choose "Inline script" or "Script file"
                   The environment variables ($servicePrincipalId, $servicePrincipalKey, $tenantId) are                            available for script. We use these variables in Bash script as,
                   
                   # Export to ARM_* env var for Terraform from inline script, 
                   # then do terraform init plan apply
                   export ARM_CLIENT_ID=$servicePrincipalId
                   export ARM_CLIENT_SECRET=$servicePrincipalKey
                   export ARM_TENANT_ID=$tenantId
                   export ARM_SUBSCRIPTION_ID=$(az account show --query id --output tsv)
                   
                   These environment variables are only available for the duration of the pipeline job and are                     not persisted or exposed outside the job.
                e) Script: Enter Azure CLI commands (for example, 'az account show' or 'az group list') and                        save pipeline.
           ii) Using Terraform task -
                a) create terraform task, select ARM service connection, set the Terraform task to use that                        service connection, 
                   - enable “Use Env Vars for Authentication” in the Terraform task UI, the task will                      automatically set ARM_CLIENT_ID, ARM_CLIENT_SECRET (or OIDC token), ARM_TENANT_ID, and                          ARM_SUBSCRIPTION_ID for that Terraform task based on the selected service connection.
                     Or,
                   - 'Use Entra ID for Authentication' option is when we want to authenticate using Azure AD                         (Entra ID) credentials, such as managed identities or user-based authentication. 

                   For service principals, stick with "Use Env Vars for Authentication". Means, the needed SP                      details are automatically injected into the environment for that task, allowing Terraform 
                   to authenticate. 
                     (Alternatively, we add variable to env var option under task)

-------------------------------------------------------------------------------------------------------------
Terraform Commands:
-------------------
(Part of Bootstrap plan- manually create resources at azure then shift to azure devops cicd pipeline)

>> After changing data, resource blocks' code etc to refresh statefile free from errors
# Clean state
$ rm -rf .terraform .terraform.lock.hcl terraform.tfstate*
and also,
# Remove local files after moving backened to azure storage remote
$ rm -f errored.tfstate plan.tfplan terraform.tfstate terraform.tfstate.backup


# Fresh start
$ terraform init > validate > plan > apply 

# Always better to preview and lock the exact plan
$ terraform plan -out=plan.tfplan
$ terraform apply plan.tfplan


>> After adding the backened block to move statefile to created storage account, use
# initialize the remote backend
$ terraform init -upgrade
# plan show no changes (verify)
$ terraform plan
# show list of resources on statefile
$ terraform state list
# unlock statefile (if needed)
$ terraform force-unlock

# Check remote state (will receive a json from remote)
$ terraform state pull
# Confirm backened
$ terraform providers


----Start-Error-handling----
If change the name in block after resource type, like changing 'mytfstate' to 'prodmyapp' as
``` resource "azurerm_storage_account" "prodmyapp" {...} ``` and it destroyed existing resources before recreating them, causing a DNS lookup failure for the storage account and backend state access issues.

Errors - Failed to save state, Failed to persist state to backend, Error releasing the state lock, A resource (RG) with the ID already exists needs to be imported into the State - "Error releasing the state lock 
Error message: failed to retrieve lock info: executing request: Head 
"https://prodmyapptfstate01.blob.core.windows.net/mytfstate/terraform.tfstate": dial tcp: lookup prodmyapptfstate01.blob.core.windows.net on 172.31.0.2:53: no such host".

> Follow Steps - 

Summary of recovery sequence - force-unlock > import RG > state rm old entries > init -upgrade > validate and continue.
#Force unlock the state lock if get below like error
$ terraform force-unlock <lock-id-from-error>
Example error case (contains lock id) - "Error: Error acquiring the state lock State locked to player 12345678-abcd-1234-efgh-1234567890ab at rg_name/myaccount/mytfstate/terraform.tfstate"

Skip to next step,

Summary of recovery sequence - Recreate RG, storage account + container > Initialize backend > Import existing resources (RG, SA, SC) > Validate and continue.
#In our case, lock is broken due to storage account deletion, so force-unlock won't work. Terraform already saved recovery state locally, we initialize it manually to backend later after recreation, verify recovery statefile exists,
$ ls -la errored.tfstate

#Recreate infrastructure manually
$ az group create --name myTFResourceGroup --location "Australia East"
az storage account create --name prodmyapptfstate01 --resource-group myTFResourceGroup \
  --location "Australia East" --sku Standard_LRS --kind StorageV2
az storage container create --name mytfstate --account-name prodmyapptfstate01

#Initialize terraform
$ terraform init -upgrade

#Import all existing resources into state
- Import Resource Group
$ terraform import azurerm_resource_group.prodmyapp /subscriptions/2b2f02f7-dde2-47db-974c-47d2182721ae/resourceGroups/myTFResourceGroup
- Import Storage Account  
$ terraform import azurerm_storage_account.prodmyapp /subscriptions/2b2f02f7-dde2-47db-974c-47d2182721ae/resourceGroups/myTFResourceGroup/providers/Microsoft.Storage/storageAccounts/prodmyapptfstate01
- Import Storage Container
$ terraform import azurerm_storage_container.prodmyapp https://prodmyapptfstate01.blob.core.windows.net/mytfstate

#Clean up any remaining old state entries with mytfstate listed
$ terraform state list
azurerm_resource_group.mytfstate
azurerm_storage_account.mytfstate
azurerm_storage_container.mytfstate
then, remove
$ terraform state rm azurerm_resource_group.mytfstate
$ terraform state rm azurerm_storage_account.mytfstate
$ terraform state rm azurerm_storage_container.mytfstate

#Validate and proceed
$ terraform plan
----End-Error-handling----

-------------------------------------------------------------------------------------------------------------
How to use `terraform import` in both **Azure** and **AWS** contexts, either from a **CI/CD pipeline** or **locally**. 

Step-by-step:

1. Understanding `terraform import`

* `terraform import` is used to 'bring existing infrastructure under Terraform management'.
* It DOESN'T generate `.tf` configuration automatically; we must write the resource block yourself.
* It **links an existing resource** in your cloud account to a Terraform resource in your state file.

Syntax:
$ terraform import [options] <RESOURCE_ADDRESS> <RESOURCE_ID>
* `RESOURCE_ADDRESS` → The Terraform resource name in your `.tf` files, e.g., `aws_s3_bucket.my_bucket`.
* `RESOURCE_ID` → The actual ID of the resource in the cloud provider.

2. Using `terraform import` Locally

### **Step-by-step (AWS/Azure example)**

- Create a `.tf` resource block (without applying yet):

resource "aws_s3_bucket" "my_bucket" {
  bucket = "my-existing-bucket"
}

resource "azurerm_resource_group" "my_rg" {
  name     = "existing-rg"
  location = "East US"
}

- Initialize Terraform:
$ terraform init

- Import the resource:
$ terraform import aws_s3_bucket.my_bucket my-existing-bucket
$ terraform import azurerm_resource_group.my_rg /subscriptions/<SUBSCRIPTION_ID>/resourceGroups/existing-rg


- Check state:
$ terraform state list
$ terraform state show azurerm_resource_group.my_rg

- Run `terraform plan` > differences > update `.tf` file > match actual resource attributes.

3. Using `terraform import` in a Pipeline (CI/CD)

If running Terraform in a pipeline (GitHub Actions, Azure DevOps, Jenkins, etc.), we need to **authenticate** with cloud provider and ensure Terraform can write to the state backend.

### **Pipeline Steps Example (AWS)**

```yaml
steps:
  - name: Checkout code
    uses: actions/checkout@v3

  - name: Setup Terraform
    uses: hashicorp/setup-terraform@v2

  - name: Configure AWS credentials
    uses: aws-actions/configure-aws-credentials@v2
    with:
      aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
      aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
      aws-region: us-east-1

  - name: Terraform Init
    run: terraform init

  - name: Terraform Import
    run: terraform import aws_s3_bucket.my_bucket my-existing-bucket

  - name: Terraform Plan
    run: terraform plan
```

4. **Summary**

* `terraform import` is for linking existing resources to Terraform.
* Syntax is provider-specific but conceptually the same.
* `Write the resource block before importing.` Terraform won’t create `.tf` files for you.
* Check resource IDs carefully.** AWS uses names/ARNs; Azure uses full resource IDs.
* Locally: run `terraform init` > `terraform import` > `terraform plan`.
* In pipelines: authenticate > init > import > plan > apply (optional).
* `Use remote state in pipelines` to prevent state conflicts and also if want the state shared across runs.
* Always run `terraform plan` after import** to sync your config with real resource settings.
* Always verify and adjust the `.tf` config after import.
* Automate carefully** — importing is usually a `one-time operation` per resource, not a repeated pipeline step.

---

# Scenario - *Exactly* the real-world Terraform scenario people hit in production.

* ./ Remote backend **already configured** (S3 / Azure Blob)
* ./ Terraform is running in production
*  X Someone creates a resource **manually in the cloud dashboard**
*  X That resource **does not exist** in your `.tf` files
*  ? What happens next?
---

> Reality in cloud account, Terraform state (remote backend) and Terraform configuration (.tf)

Cloud account:
  - Resource A (Terraform-managed)
  - Resource B (Terraform-managed)
  - Resource C (MANUALLY created)

terraform.tfstate:
  - Resource A
  - Resource B

main.tf:
  - Resource A
  - Resource B

As Terraform NEVER SCANS ACCOUNT, Terraform has NO idea Resource C exists.
It only knows about .tf and statefile. This is called 'configuration drift outside Terraform'.
---

> Now, when pipelines / terraform plan runs
$ terraform plan
# Result:
* ./ No changes
*  X Resource C is ignored with No warning & No error

---
*** Handling in Production (IMPORTANT) ***

## Step-by-step workflow - To bring the manually created resource under Terraform control SAFELY.

-> Step 1: Identify the resource details
From dashboard / CLI, find out Name, ID, Region, Resource group / VPC / subnet, Tags. 
Example: AWS S3 bucket: `prod-logs-bucket`, Azure RG: `prod-rg-extra`.

-> Step 2: Add resource block to `.tf` (NO APPLY) - Examples AWS/Azure:

resource "aws_s3_bucket" "prod_logs" {
  bucket = "prod-logs-bucket"
}

resource "azurerm_resource_group" "prod_extra" {
  name     = "prod-rg-extra"
  location = "East US"
}

-> Step 3: Initialize (uses remote backend)
$ terraform init
Terraform connects to S3 / Azure Blob where Existing production state is located.

-> Step 4: Import the resource into remote state (KEY STEP). AWS/Azure examples,
$ terraform import aws_s3_bucket.prod_logs prod-logs-bucket
$ terraform import azurerm_resource_group.prod_extra \
/subscriptions/<SUB_ID>/resourceGroups/prod-rg-extra
Resource is now written into **remote state**. Safe for pipelines and team.

-> Step 5: Inspect imported state AWS/Azure
$ terraform state show aws_s3_bucket.prod_logs
$ terraform state show azurerm_resource_group.prod_extra
This shows the **real config** from cloud.

-> Step 6: Reconcile `.tf` with reality. Now running plan, shows '~ update in-place'.
$ terraform plan

Reason - Dashboard defaults ≠ Terraform defaults, Missing attributes, Tags differ, Encryption flags, policies, etc. Now fix `.tf` file until it shows 'No changes. Infrastructure is up-to-date.'.

-> Step 7: Commit and let pipeline run
$ terraform plan
$ terraform apply
The imported resource is **fully Terraform-managed**.
---

## What NOT to do in production
Don’t let pipelines run `terraform import` repeatedly
Don’t apply before import
Don’t manually edit state files
Don’t ignore dashboard-created resources long-term

---
## Recommended production rule (golden rule)
Everything in production must be either: Managed by Terraform Or explicitly documented as out-of-band.

Best teams:
* Lock down dashboards (RBAC)
* Force infra changes through PRs
* Use `terraform plan` as a gate
---

## Mental model 
.tf files  → desired state
.tfstate   → known state
Cloud      → actual state
---

????????
* Make a **ready-to-use example for both AWS and Azure pipelines** showing how to import **multiple resources automatically**.
* Show how to **detect unmanaged resources**
* Explain **drift detection tools**
* Share a **safe “import day” checklist for prod**
* Walk through a **multi-resource bulk import**
* key vault/key visibility on dashboard - add private endpoint + firewall (portal visibility changes again there)
?????????
-------------------------------------------------------------------------------------------------------------
Scenario - Suppose we are doing terraform pipeline as SP not as user and we create key vault and key, then 
we want to see the key created inside key vault > keys using dashboard as a user. 

Method 1 - (Recommended) Manual assignment of role (to enable permissions to view)
$ az role assignment create \
  --role "Key Vault Crypto Officer" \
  --assignee usrlsothdevops@gmail.com \
  --scope /subscriptions/2b2f02f7-dde2-47db-974c-47d2182721ae/resourceGroups/myTFResourceGroup/providers/Microsoft.KeyVault/vaults/prodmyappkv

# Industry best practice
# After doing this Required Microsoft Graph permission `Directory.Read.All` will not be required.

Method 2 - (Terraform Only) Use resource block for role assignment to user using its' `object_id`.

resource "azurerm_role_assignment" "human_kv_crypto_officer" {
  scope                = azurerm_key_vault.prodmyapp.id
  role_definition_name = "Key Vault Crypto Officer"
  principal_id         = "USER_OBJECT_ID_HERE"
}

# Principal - Hardcode object IDs of known humans or service accounts. Like DevOps lead or security engineer’s object IDs. No AzureAD provider block required, No Graph permissions required. It's Deterministic.
# Enables the Object id user to view the key or other resources on dashboard.

-------------------------------------------------------------------------------------------------------------
Recommended Production Pattern

(Need az cli on ec2, resources such as resource group, storage account, container (and Key) and configure the backend.tf and yaml file for Azure DevOps pipeline configuration for automation.)

--
Initial setup - 
Authenticate manually via logging-in to azure CLI and/or env vars (need to export subscription_id for
terraform) on EC2 instance. or export all SP secrets to env vars.
Create resources such as resource group, storage account, container (and Key).

--
---
Automation setup - 

Configure the backend.tf and push statefile to Azure Container. 
Create Key Vault separate for dev/test/prod.
Store secrets securely - Upload SP secrets and other credentials to Key Vault using CLI or terraform. When
uploading SP secrets using terraform available from az cli context use data block ``` data "azurerm_client_config" "current" {} ```. 
Key Vault Access Policy - Service Principal or Managed Identity with 'get' permission to access secrets.
Export client secret to env vars, as 'data.azurerm_client_config.current' cannot fetch it, and to use from env use 'var.arm_client_id' as value to key 'value'.


Configure CI/CD or automation agents to inject env vars securely or use managed identities.

-remove use_cli from backened
-Use data blocks to pull SP secrets from key vault, to be used in provider block for authentication
-From Azure DevOps dashboard, add Service Principal as a Variable Group with Key Vault integration: 
Azure DevOps Project > Pipeline > Library > Variable Groups > + Variable Group > Add Name & Description to Variable Group > Enable toggle switch button to link an Azure key vault and map selective vault secrets to this variable group > Select Azure subscription 'az-classic-conn' > Select Key vault name 'prodmyappkv' >
Variables > + Add > Select all secrets needed > Save. 

For YAML Pipeline, create and use file 'azure-pipelines.yaml' in same dir as of .tf files, push to github. Connect GitHub repo in DevOps Pipelines > New Pipeline > GitHub > Select Repository > Existing Azure Pipelines YAML file > Select YAML file. 

For Classic Pipeline ?
---
----
Future runs - 
Terraform authenticates using injected creds or managed identity, 
fetches secrets dynamically from Key Vault, and applies infrastructure changes.
----
Terraform State Security: Store Terraform state remotely (e.g., in Azure Storage with access controls), and enable state file encryption.

Sensitive Outputs: Mark any outputs of secrets or IDs as 'sensitive = true' in Terraform, or avoid outputting them altogether.
--------------------------------------------------------------------------------------------------------------
Case - Want to run terraform commands locally

- We initially ran Terraform locally, so our state was stored on the local filesystem.
- Then we moved the statefile to Azure Storage (azurerm backend) and continued creating resources.
- Now on our EC2/local Terraform, Terraform detects that the backend in your code (azurerm storage) is different from the previous local backend.

Since we’ve already moved our statefile to Azure Storage, we don’t need to migrate again. We just want Terraform to reconfigure to use the remote backend:

$ terraform init -reconfigure

This will:
- Reinitialize the Terraform working directory
- Point Terraform to the Azure Storage backend
- Keep all the existing state in the backend
- Avoid overwriting anything

or, if showing changes after -reconfigure should always follow
how to use terraform import when doing azure or aws form pipeline or locally?
terraform init -reconfigure or init > terraform import > terraform plan > terraform apply
--------------------------------------------------------------------------------------------------------------
## Rotate secrets regularly and enable alerting

A) Rotation:
	1) Manually: Periodically update the secret value in Key Vault (new SP secret/password, DB password, 		etc.). Each update creates a new secret version; update the downstream system (e.g., SP or DB) to use the new value.
	2) Automated: Use: 
		a) Event Grid + Azure Function / Logic App that listens for “SecretNearExpiry” events and 			rotates the secret (creates new value, writes to Key Vault, updates the dependent resource).
		b) For keys, use key rotation policies configured on Key Vault keys.
​
B) Alerting:
	1) Use Azure Monitor / Alerts on:
		a) Key Vault logs (audit log, secret access, secret change events).
		b) “SecretNearExpiry” events, unauthorized access attempts, or abnormal access patterns.
	2) Route alerts to email, Teams, or incident tools.

​> Secret Rotation: When rotating secrets, update both Key Vault and credentials used by automation/bots running Terraform.
-------------------------------------------------------------------------------------------------------------
*** Use artifact 'tfplan' method for production with approval gates ***

## Approval Gates - (configure in azure-pipelines.yaml)

Plan Stage → [APPROVAL GATE] → Apply Stage
         ↓                    ↓
   Creates tfplan          Deploys infrastructure

Pipeline Flow - Plan Stage > [PAUSE: Manual Approval Required] > Apply Stage 

Prevents: Accidental production deployments without review.
Pipeline stops at the gate → person approves/rejects → pipeline continues/stops.

Methods to Add Approval Gates:

Method 1: Environments (Recommended for YAML) - 
Goto Organization > Project > Pipelines > Environments > Create environment > Name 'prod' > Description 'Production environment for Terraform deployments' > Resource 'None'> Create > Approvals and checks > Approvals > Select Approver/Add email > Control options > Timeout > Create. 

*Pipeline runs > Plan completes & Pipeline pauses > Go to Environments > prod shows "Waiting for approval" > Click Approve > Apply runs

Add YAML Code under 'jobs:' as

  # ✅ APPROVAL GATE via Environment
  - deployment: ProductionDeployment
    displayName: 'Deploy to Production'
    environment: 'prod'  # Create this environment in Azure DevOps first
    strategy:
      runOnce:           # standard deployment pattern
        deploy:
          steps:
          - task: TerraformInstaller@0  # Reinstall for consistency
          
          # DOWNLOAD plan artifact
          - task: DownloadPipelineArtifact@2
            inputs:
              buildType: 'current'
              artifactName: 'tfplan'
              targetPath: 'azuretf/simpletf/'


Method 2: Manual Approval Check (No environments/dashboard usage needed)
 Plan > Approval > Apply

Pipeline Flow - 
Plan completes > publishes tfplan artifact > Approval stage > **PAUSES** at "ManualValidation" > sends emails > I/team review plan >Click pipeline > "Approval stage" > click **Approve** or **Reject** buttons > if approved - Apply 

Perfect for quick production gates without environment setup.

Add YAML Code after stage plan as
- stage: Approval
  dependsOn: Plan
  condition: succeeded()
  jobs:
  - job: ManualApproval
    pool: server  # Uses Azure DevOps server (no agent needed)
    steps:
    - task: ManualValidation@0
      timeoutInMinutes: 4320  # 3 days timeout (auto-rejects after timeout)
      inputs:
        notifyUsers: |           # List of email addresses (notifications sent)
          you@company.com
          team@company.com
        instructions: |          # Custom message with plan details
          **Review the Terraform Plan above carefully.**
          
          This will deploy:
          - Resource Group: myTFResourceGroup (Australia East)
          - Storage Account: prodmyapptfstate01  
          - Storage Container: mytfstate
          - Key Vault: prodmyappkv
          
          **Approve** to proceed with deployment.
          **Reject** to stop pipeline.
          
          tfplan artifact available for download.
        onTimeout: 'reject'      # stops pipeline if no approval

- stage: Apply
  dependsOn: Approval
  condition: succeeded()
  jobs:
  - job: Apply
    steps:
    - task: TerraformInstaller@0  # Reinstall for consistency
    
    # DOWNLOAD plan artifact
    - task: DownloadPipelineArtifact@2
      inputs:
        buildType: 'current'
        artifactName: 'tfplan'
        targetPath: 'azuretf/simpletf/'

    # Add, format and use/continue locs with tasks for init and apply mentioned at end of file.
    
*** Avoid artifact 'tfplan' method and Approval Gates for dev/test ***

Plan → Apply (same workspace, no artifacts)

Commit > Push > Watch it deploy end-to-end.
Once tested successfully > add back approval gates for production safety.
Ideal for verifying your bootstrap pipeline works before adding gates.

stages:
- stage: Deploy
  jobs:
  - job: Deploy
    steps:
    - task: TerraformInstaller@0
      inputs:
        terraformVersion: '1.14.3'  # Match version

    - task: TerraformTaskV4@4
      inputs:
        provider: 'azurerm'
        command: 'init'
        workingDirectory: 'azuretf/simpletf' # since files in terraform_automation_IaC/azuretf/simpletf/
        backendServiceArm: '$(serviceConnection)'
        backendAzureRmResourceGroupName: 'myTFResourceGroup'
        backendAzureRmStorageAccountName: 'prodmyapptfstate01'
        backendAzureRmContainerName: '$(containerName)'
        backendAzureRmKey: '$(key)'
        environmentServiceNameAzureRM: '$(serviceConnection)'

    - task: TerraformTaskV4@4
      inputs:
        provider: 'azurerm'
        command: 'plan'
        workingDirectory: 'azuretf/simpletf'   # since files in terraform_automation_IaC/azuretf/simpletf/
        environmentServiceNameAzureRM: '$(serviceConnection)'
        commandOptions: '-detailed-exitcode -var="arm_client_secret=$(ARM_CLIENT_SECRET)"'  # Optional: pass secrets

    - task: TerraformTaskV4@4
      inputs:
        provider: 'azurerm'
        command: 'apply'
        workingDirectory: 'azuretf/simpletf'   # since files in terraform_automation_IaC/azuretf/simpletf/
        environmentServiceNameAzureRM: '$(serviceConnection)'
        commandOptions: '-auto-approve'
--------------------------------------------------------------------------------------------------------------




